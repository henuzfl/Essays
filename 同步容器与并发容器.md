---
title: 同步容器与并发容器
tags: 新建,模板,小书匠
grammar_cjkRuby: true
---



[toc]
## 1.同步容器
在java中，同步容器包括两类：
1. Vector、Stack、Hashtable
2. Collections类中提供的静态工厂方法创建的类，比如通过Collections.synchronizedList创建一个线程安全的list。

这些同步容器都是使用**synchronized**进行了同步，Vector类似于ArrayList，可以看成可以自增的数组。Stack继承与Vector，其实就是Vector的特殊实现。Hashtable很奇怪，命名方式都不符合Java的规范，可见有多老，使用同步实现了Map接口。Collections的静态工厂方法就是将线程不安全的List、Set、Map使用**代理设计模式**增加了同步操作。
### 1.1 安全性问题
同步容器是线程安全的这个说法没有问题，add、remove、size等操作都使用synchronized进行了同步。当时对于**复合操作**来说，就需要额外的加锁来保护复合操作。常见的复合操作有：迭代、跳转（根据指定顺序找到当前元素的下一个元素）以及**先检查后执行**操作。

#### ConcurrentModificationException异常  

当容器在迭代的过程中被修改，就会抛出这个异常。具体的实现是通过一个容器变化计数器modCount（当add、remove操作时该字段+1），在迭代之前，赋值expectedModCount=modCount，然后迭代过程中如果迭代器外部有修改了容器，则二者的值就会不一样，每次迭代的时候都会检测这两个值是否相当。除此之外，还要注意**隐藏迭代器**，比如容器的toString，retainAll，containsAll，removeAll等操作，实际上就包含了迭代操作。

为了解决同步容器复合操作带来的安全性问题，可以使用对容器加锁，还要特别注意包含隐藏迭代器的操作，这种情况下也需要加锁。同步中迭代操作除了加锁还有一种替代方法是**clone容器**，并在副本上进行迭代，由于副本封闭在线程内，其他线程不会再其迭代的期间对其修改，就会避免抛出ConcurrentModificationException。当然了这种操作会存在显著的性能开销，要综合各个因素来考虑。
### 1.2 性能问题
同步容器的访问都是线性化的，也就是无论什么时候都只有一个线程可以访问容器的状态，以此来实现线程的安全性。另外，为了使用同步容器过程中的复合操作也是线程安全的，就需要在复合操作的过程中在外层对容器加锁，特别是针对于迭代操作，数据量比较大的情况下在迭代的过程中无法访问容器。

## 2.并发容器
由于同步容器的安全性以及性能问题，在jdk5提供了多种并发容器类用来替代同步容器，可以极大地提高伸缩性并降低风险。
### 2.1 ConcurrentHashMap
>用来替代Hashtable
#### 锁分段
> 对一组独立对象上的锁进行分解，比如ConcurrentHashMap的实现使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中N个散列桶由N mod 16个锁来保护。假如散列函数合理，并且关键字能够实现均匀分布，那么这大约能把对锁的请求减少到原来的1/16。 

在jdk中，ConcurrentHashMap是由**Segment**数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。结构如下：
![Alt text](./1519286378613.png)
##### jdk7中的关键源码

segment数组的初始化：
```java
if (concurrencyLevel > MAX_SEGMENTS)
    concurrencyLevel = MAX_SEGMENTS;
int sshift = 0;
int ssize = 1;
while (ssize < concurrencyLevel) {
    ++sshift;
    ssize <<= 1;
}
this.segmentShift = 32 - sshift;
this.segmentMask = ssize - 1;
if (initialCapacity > MAXIMUM_CAPACITY)
    initialCapacity = MAXIMUM_CAPACITY;
int c = initialCapacity / ssize;
if (c * ssize < initialCapacity)
    ++c;
int cap = MIN_SEGMENT_TABLE_CAPACITY;
while (cap < c)
    cap <<= 1;
Segment<K,V> s0 =
    new Segment<K,V>(loadFactor, (int)(cap * loadFactor),
                     (HashEntry<K,V>[])new HashEntry[cap]);
Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];
```
默认情况下，concurrencyLevel=16，由上面的代码可知segments数组的长度ssize通过concurrencyLevel计算得出。为了能通过按位与的哈希算法来定位segments数组的索引，必须保证segments数组的长度是2的N次方（power-of-two size），所以必须计算出一个是大于或等于concurrencyLevel的最小的2的N次方值来作为segments数组的长度。假如concurrencyLevel等于14，15或16，ssize都会等于16，即容器里锁的个数也是16。
```java
private static int hash(int h) {
    // Spread bits to regularize both segment and index locations,
    // using variant of single-word Wang/Jenkins hash.
    h += (h <<  15) ^ 0xffffcd7d;
	h ^= (h >>> 10);
	h += (h <<   3);
	h ^= (h >>>  6);
	h += (h <<   2) + (h << 14);
	return h ^ (h >>> 16);
}
```
可以看到会首先使用Wang/Jenkins hash的变种算法对元素的hashCode进行一次再哈希，其目的是为了减少哈希冲突，使元素能够均匀的分布在不同的Segment上，从而提高容器的存取效率。
```java
public V put(K key, V value) {
    Segment<K,V> s;
    if (value == null)
        throw new NullPointerException();
    int hash = hash(key.hashCode());
    int j = (hash >>> segmentShift) & segmentMask;
    if ((s = (Segment<K,V>)UNSAFE.getObject         
         (segments, (j << SSHIFT) + SBASE)) == null) 
        s = ensureSegment(j);
    return s.put(key, hash, value, false);
}
```
ConcurrentHashMap的插入操作，可以看出，首先计算hash，得到segment的编号，然后得到改变好segment，如果segment为空则初始化segment，然后将数据插入到segment中的HashEntry数组中。此类操作只需要获得一个segment上的显式锁即可，同理：remove、containKey、replace等操作也是如此。
```java
public void clear() {
    final Segment<K,V>[] segments = this.segments;
    for (int j = 0; j < segments.length; ++j) {
        Segment<K,V> s = segmentAt(segments, j);
        if (s != null)
            s.clear();
    }
}
```
ConcurrentHashMap的clear操作，看一看出，需要遍历segment数组，然后执行segment的clear操作，也就是这一个操作需要获得segment数组所有的显式锁，同理：size、isEmpty等操作也是如此，其中size操作有一种情况例外，size操作先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小，判断容器是否变化还是采用modCount字段，核心源码如下：
```java
 int retries = -1;
 for (;;) {
	if (retries++ == RETRIES_BEFORE_LOCK) {
    for (int j = 0; j < segments.length; ++j)
        ensureSegment(j).lock(); 
    }
    sum = 0L;
    size = 0;
    overflow = false;
    for (int j = 0; j < segments.length; ++j) {
        Segment<K,V> seg = segmentAt(segments, j);
        if (seg != null) {
           sum += seg.modCount;
           int c = seg.count;
           if (c < 0 || (size += c) < 0)
               overflow = true;
        }
    }
    if (sum == last)
       break;
    last = sum;
 }
```
#### 额外的原子操作
由于ConcurrentHashMap不能被加锁来执行独占访问，因此在客户端无法通过加锁来创建新的原子操作，因此一些常见的复合操作在ConcurrentMap中都已经有声明，比如复合操作：
* 如何没有则添加
```java
V putIfAbsent(K key, V value)
```
* 只有当key被映射到V才移除
```java
boolean remove(Object key, Object value)
```
* 当key被映射到oldValue时才替换为newValue
```java
boolean replace(K key, V oldValue, V newValue)
```
* 当key被映射到某个值时才替换为newValue。
```java
V replace(K key, V value)
```


### 2.2 ConcurrentSkipListMap
>用来替代ConcurrentTreeMap
### 2.3 CopyOnWriteArrayList
>在遍历操作为主要操作的情况下替代同步的List，类似的CopyOnWriteArraySet来替代同步的Set，
> CopyOnWrite即写入时复制，当然不止字面意义上的写入操作了，删除、更新等需要复制，容器的底层是一个数组，这个数组本身是不会修改的，也就时当容器需要修改时，会创建和发布这个数组的一个副本，然后在这个副本上进行更新操作，更新完成之后再赋值给本身的数组。多个线程可以同时对其迭代，而且不会抛出ConcurrentModificationException，返回的元素与创建迭代器的时候的元素一致。  

* **适用场景**：每次修改容器都会复制数组，会造成一定的开销，特别是当容器规模非常大的时候。仅当迭代操作远远多于修改操作的时候，才使用CopyOnWrite容器，比如说事件通知系统，需要迭代已经注册监听器链表，并且调用每一个监听器，注册和注销的操作远远少于接受事件通知的操作。
#### 存在的问题
* **内存占用率**：在容器进行更新操作操作的时候，内存里会同时驻扎两个底层数据对象的内存，旧的对象和新更新的对象。如果对象规模比较大，可能会造成频繁的垃圾回收，影响性能。
* **数据一致性**：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。
#### 关键源码解析
```java
    public boolean add(E e) {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            Object[] elements = getArray();
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements, len + 1);
            newElements[len] = e;
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();
        }
    }
```
可以看出，容器在增加一个容器的时候，会新建一个比之前底层数组长度+1的新的数组，然后把之前数据元素复制给新数组，最后把新的数组赋值给之前的数组。其他更新操作与之类似。
### 2.4 Queue与BlockingQueue
#### 生产者消费者模式
#### ConcurrentLinkedQueue

